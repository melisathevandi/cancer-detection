{"cells":[{"cell_type":"markdown","metadata":{"id":"WW6jFY_KHNh1"},"source":[]},{"cell_type":"markdown","metadata":{"id":"jBVuKT4H9qjA"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_P9LS8spHAu1","executionInfo":{"status":"ok","timestamp":1730640061924,"user_tz":-480,"elapsed":335,"user":{"displayName":"Vicelya Visakha","userId":"01818935523919752820"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import make_scorer\n","from sklearn.metrics import roc_auc_score\n","from imblearn.over_sampling import SMOTE\n","from collections import Counter\n","from imblearn.pipeline import Pipeline as ImbPipeline\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nTi7tmui95nv"},"source":["# Load the data"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Cqrg0EjcHYPa","executionInfo":{"status":"ok","timestamp":1730640063204,"user_tz":-480,"elapsed":932,"user":{"displayName":"Vicelya Visakha","userId":"01818935523919752820"}}},"outputs":[],"source":["train_data = np.genfromtxt('Train_Set.csv', delimiter=',', dtype=str, skip_header=1)\n","test_data = np.genfromtxt('Test_Set.csv', delimiter=',', dtype=str, skip_header=1)\n","\n","def convert_labels(data):\n","    labels = data[:, -1]\n","    labels = np.where(labels == 'healthy', 0, 1)\n","    features = data[:, :-1].astype(float)\n","    return features, labels\n","\n","X_train, y_train = convert_labels(train_data)\n","X_test, y_test = convert_labels(test_data)"]},{"cell_type":"markdown","metadata":{"id":"3Dd5_9Gipqpw"},"source":["# Feature Scaling\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"d2vTU6d1pwv_","executionInfo":{"status":"ok","timestamp":1730640063204,"user_tz":-480,"elapsed":4,"user":{"displayName":"Vicelya Visakha","userId":"01818935523919752820"}}},"outputs":[],"source":["scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"EBgwyJEX-BTC"},"source":["# Preprocess the data"]},{"cell_type":"markdown","metadata":{"id":"8MwbIi6x-SbI"},"source":["### Feature Reduction: PCA"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CxKI65iAJfrg","outputId":"41ee8e91-d77a-43e2-acbe-36ab5cf4f857","executionInfo":{"status":"ok","timestamp":1730640063204,"user_tz":-480,"elapsed":4,"user":{"displayName":"Vicelya Visakha","userId":"01818935523919752820"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of components retained by PCA: 20\n"]}],"source":["pca = PCA(n_components = 20)\n","X_train = pca.fit_transform(X_train)\n","X_test = pca.transform(X_test)\n","\n","print(f\"Number of components retained by PCA: {X_train.shape[1]}\")"]},{"cell_type":"markdown","metadata":{"id":"kpcEd1uQrToQ"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Tuning Hyperparameter For Each Model Using GridSearchCV\n"]},{"cell_type":"markdown","metadata":{"id":"_EsZUF5bQQUb"},"source":["We use a Pipeline with GridSearchCV so that SMOTE is applied only on the training folds within each cross-validation split"]},{"cell_type":"markdown","metadata":{"id":"_v0xXNsJPoN_"},"source":["### Define Specificity"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_P-Bt0gSPmL4","executionInfo":{"status":"ok","timestamp":1730640063204,"user_tz":-480,"elapsed":2,"user":{"displayName":"Vicelya Visakha","userId":"01818935523919752820"}}},"outputs":[],"source":["# Define the specificity scoring function\n","def specificity_score(y_true, y_pred):\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    return tn / (tn + fp) if (tn + fp) > 0 else 0\n","\n","# Create the custom specificity scorer\n","scoring = {'specificity': make_scorer(specificity_score)}"]},{"cell_type":"markdown","metadata":{"id":"ZCgPR4bxO7WS"},"source":["### Search for the best hyperparameter for Decision Tree Clasification"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P4NalPY7PRM5","outputId":"d160f6fa-f4ac-4475-c060-8868bb3ccb44","executionInfo":{"status":"ok","timestamp":1730640111399,"user_tz":-480,"elapsed":48197,"user":{"displayName":"Vicelya Visakha","userId":"01818935523919752820"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n","Best Parameters: {'dt__class_weight': None, 'dt__criterion': 'gini', 'dt__max_depth': 30, 'dt__max_features': None, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 2}\n","Best Specificity Score (Cross-Validation): 0.65\n"]}],"source":["# Define the parameter grid for GridSearchCV\n","param_grid = {\n","    'dt__criterion': ['gini', 'entropy'],\n","    'dt__max_depth': [None, 10, 20, 30, 40],\n","    'dt__min_samples_split': [2, 5, 10],\n","    'dt__min_samples_leaf': [1, 2, 5],\n","    'dt__max_features': [None, 'sqrt', 'log2'],\n","    'dt__class_weight': [None, 'balanced']\n","}\n","\n","# Create the Pipeline\n","pipeline = ImbPipeline([\n","    ('smote', SMOTE()), # smote done for each fold\n","    ('dt', DecisionTreeClassifier(random_state=42))\n","])\n","\n","# Set up the GridSearchCV to score based on specificity only\n","grid_search = GridSearchCV(\n","    estimator=pipeline,\n","    param_grid=param_grid,\n","    scoring=scoring,\n","    refit='specificity',\n","    cv=5,\n","    verbose=2,\n","    n_jobs=-1\n",")\n","\n","# Fit GridSearchCV to the training data\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters and best specificity score\n","best_params_DT = grid_search.best_params_\n","best_specificity = grid_search.best_score_\n","\n","# Print the best parameters and best specificity score\n","print(\"Best Parameters:\", best_params_DT)\n","print(\"Best Specificity Score (Cross-Validation):\", best_specificity)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0YCjvHsOw-A","outputId":"98a59f02-3069-4a05-f573-194274a74e6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"]}],"source":["# Define the parameter grid for GridSearchCV\n","param_grid = {\n","   'rf__max_depth': [2 ,5, 10, 15],\n","   'rf__n_estimators': [50, 100, 150],\n","   'rf__min_samples_split': [10, 15, 20],\n","   'rf__min_samples_leaf': [5, 8, 10],\n","   'rf__max_features': ['sqrt', 0.5, 0.75],\n","   'rf__bootstrap': [True]\n","}\n","\n","# Create the Pipeline\n","pipeline = ImbPipeline([\n","    ('smote', SMOTE()), # smote done for each fold\n","    ('rf', RandomForestClassifier(random_state=42))\n","])\n","\n","# Set up the GridSearchCV to score based on specificity only\n","grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid,\n","                           scoring=scoring,\n","                           refit='specificity',  # Refitting using the specificity score\n","                           cv=5,  # 5-fold cross-validation\n","                           verbose=2,  # Verbosity level\n","                           n_jobs=-1)  # Use all available cores\n","\n","# Fit GridSearchCV to the training data\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters and best specificity score\n","best_params_RF = grid_search.best_params_\n","best_specificity = grid_search.best_score_\n","\n","# Print the best parameters and best specificity score\n","print(\"Best Parameters:\", best_params_RF)\n","print(\"Best Specificity Score (Cross-Validation):\", best_specificity)\n"]},{"cell_type":"markdown","metadata":{"id":"bG2vd9c-oWkr"},"source":["### Search for the best hyperparameter for Logistic Regression Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQrvKMYKrYHg"},"outputs":[],"source":["# Define a valid parameter grid including the C parameter for regularization strength\n","param_grid = [\n","    {'lr__solver': ['lbfgs'], 'lr__penalty': ['l2'], 'lr__C': [0.01, 0.1, 1, 10, 100]},\n","    {'lr__solver': ['liblinear'], 'lr__penalty': ['l1', 'l2'], 'lr__C': [0.01, 0.1, 1, 10, 100]},\n","    {'lr__solver': ['saga'], 'lr__penalty': ['l1', 'l2'], 'lr__C': [0.01, 0.1, 1, 10, 100]},\n","    {'lr__solver': ['saga'], 'lr__penalty': ['elasticnet'], 'lr__C': [0.01, 0.1, 1, 10, 100], 'lr__l1_ratio': [0.1, 0.5, 0.9]},\n","    {'lr__solver': ['sag'], 'lr__penalty': ['l2'], 'lr__C': [0.01, 0.1, 1, 10, 100]}\n","]\n","\n","# Create a pipeline\n","pipeline = ImbPipeline([\n","    ('smote', SMOTE()),\n","    ('lr', LogisticRegression(random_state=42))\n","])\n","\n","# Set up GridSearchCV to use the specificity score\n","grid_search = GridSearchCV(estimator=pipeline,\n","                           param_grid=param_grid,\n","                           scoring=scoring,\n","                           refit='specificity',  # Refitting using the specificity score\n","                           cv=5,  # 5-fold cross-validation\n","                           verbose=2,  # Verbosity level\n","                           n_jobs=-1)  # Use all available cores\n","\n","# Fit GridSearchCV to the training data\n","grid_search.fit(X_train, y_train)\n","\n","# Extract the best parameters and the best specificity score\n","best_params_LR = grid_search.best_params_\n","best_specificity = grid_search.best_score_\n","\n","# Print the best parameters and best specificity score\n","print(\"Best Parameters:\", best_params_LR)\n","print(\"Best Specificity Score (Cross-Validation):\", best_specificity)\n"]},{"cell_type":"markdown","metadata":{"id":"ABxch1N8Ov_a"},"source":["### Search for the best hyperparameter for Random Forest Classification"]},{"cell_type":"markdown","source":["### Search for the best hyperparameter for SVM"],"metadata":{"id":"XUy279nE5TJm"}},{"cell_type":"code","source":["# Define the SVM model with balanced class weights\n","svm = SVC(class_weight='balanced')\n","\n","# Set up the parameter grid\n","param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n","\n","# Use GridSearchCV with the custom scorer\n","grid_search = GridSearchCV(estimator=svm,\n","                           param_grid=param_grid,\n","                           scoring=scoring,\n","                           refit='specificity',\n","                           cv=5,\n","                           verbose=2,\n","                           n_jobs=-1\n",")\n","\n","grid_search.fit(X_train, y_train)\n","\n","# Extract the best parameters and the best specificity score\n","best_params_SVM = grid_search.best_params_\n","best_specificity = grid_search.best_score_\n","\n","# Print the best parameters and best specificity score\n","print(\"Best Parameters:\", best_params_SVM)\n","print(\"Best Specificity Score (Cross-Validation):\", best_specificity)"],"metadata":{"id":"PefwwYnE5SC2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modelling and Evaluation"],"metadata":{"id":"JBIgtIqdw9Rv"}},{"cell_type":"code","source":["smote = SMOTE(random_state=42)\n","X_train_SMOTE, y_train_SMOTE = smote.fit_resample(X_train, y_train)"],"metadata":{"id":"0Ai-gF0hEJss"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ou_YIVrWPPN"},"source":["### Test the model with the best parameter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_a3DTTHMVFTa"},"outputs":[],"source":["best_params_RF_corrected = {key.replace('rf__', ''): value for key, value in best_params_RF.items()}\n","best_params_DT_corrected = {key.replace('dt__', ''): value for key, value in best_params_DT.items()}\n","best_params_LR_corrected = {key.replace('lr__', ''): value for key, value in best_params_LR.items()}\n","\n","# Initialize models with the corrected parameters\n","rf = RandomForestClassifier(random_state=42, **best_params_RF_corrected)\n","dt = DecisionTreeClassifier(random_state=42, **best_params_DT_corrected)\n","lr = LogisticRegression(random_state=42, **best_params_LR_corrected)\n","svm = SVC(**best_params_SVM, probability = True, class_weight = \"balanced\")\n","\n","\n","# Fit models\n","lr.fit(X_train_SMOTE, y_train_SMOTE)\n","rf.fit(X_train_SMOTE, y_train_SMOTE)\n","dt.fit(X_train_SMOTE, y_train_SMOTE)\n","svm.fit(X_train, y_train)\n","\n","# Get predictions and probabilities\n","models = {'Decision Tree': dt, 'Logistic Regression': lr, 'Random Forest': rf, 'SVM': svm}\n","plt.figure(figsize=(10, 7))\n","\n","for name, model in models.items():\n","    y_pred = model.predict(X_test)\n","    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","    y_proba = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n","    fpr, tpr, _ = roc_curve(y_test, y_proba)  # ROC curve\n","    roc_auc = auc(fpr, tpr)  # AUC score\n","    specificity = tn / (tn + fp)\n","\n","    # Plot ROC curve\n","    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f}, Specificity = {specificity:.2f})')\n","\n","plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line for random guessing\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve Comparison')\n","plt.legend()\n","plt.show()\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}